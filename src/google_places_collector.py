#!/usr/bin/env python3
"""
ğŸ—ºï¸ COLLECTEUR DE DONNÃ‰ES GOOGLE PLACES - VERSION DÃ‰BUTANT
=========================================================

Ce script fait exactement ce qui est demandÃ© :
1. Se connecte Ã  l'API Google Places
2. RÃ©cupÃ¨re des restaurants Ã  Paris
3. RÃ©cupÃ¨re les avis de chaque restaurant
4. Sauvegarde en CSV et JSON
5. Upload vers AWS S3 (optionnel)

AVANTAGES vs Yelp :
- Plus facile Ã  configurer (compte Google suffit)
- 300$ gratuit par mois (largement suffisant)
- Plus de donnÃ©es disponibles
- Meilleure couverture mondiale

UTILISATION :
1. Copiez config/config_template.txt vers config/.env
2. Ajoutez votre clÃ© API Google Places
3. Lancez : python src/google_places_collector.py

Auteur : Projet Data Engineering
Date : 2024
"""

# ===== IMPORTS (bibliothÃ¨ques nÃ©cessaires) =====
import os
import json
import pandas as pd
import requests
import logging
import boto3
from datetime import datetime
from dotenv import load_dotenv
from tqdm import tqdm
import time

# ===== CONFIGURATION DU LOGGING (pour voir ce qui se passe) =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/google_places_collector.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class GooglePlacesCollector:
    """
    Classe simple pour collecter les donnÃ©es Google Places
    
    Cette classe fait tout le travail :
    - Se connecte Ã  l'API Google Places
    - RÃ©cupÃ¨re les restaurants
    - RÃ©cupÃ¨re les avis
    - Sauvegarde les donnÃ©es
    - Upload vers S3
    """
    
    def __init__(self):
        """Initialise le collecteur avec la configuration"""
        logger.info("ğŸš€ Initialisation du collecteur Google Places...")
        
        # Charger la configuration depuis le fichier .env
        self.load_config()
        
        # VÃ©rifier que tout est configurÃ©
        self.validate_config()
        
        # PrÃ©parer les dossiers de sauvegarde
        self.setup_directories()
        
        logger.info("âœ… Collecteur initialisÃ© avec succÃ¨s !")
    
    def load_config(self):
        """Charge la configuration depuis le fichier .env"""
        logger.info("ğŸ“‹ Chargement de la configuration...")
        
        # Charger le fichier .env s'il existe
        env_file = "config/.env"
        if os.path.exists(env_file):
            load_dotenv(env_file)
            logger.info(f"âœ… Configuration chargÃ©e depuis {env_file}")
        else:
            logger.warning("âš ï¸ Fichier .env non trouvÃ©, utilisation des variables d'environnement")
        
        # RÃ©cupÃ©rer les variables de configuration
        self.google_api_key = os.getenv("GOOGLE_PLACES_API_KEY", "")
        self.aws_access_key = os.getenv("AWS_ACCESS_KEY_ID", "")
        self.aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY", "")
        self.aws_region = os.getenv("AWS_REGION", "us-east-1")
        self.s3_bucket = os.getenv("S3_BUCKET_NAME", "")
        self.target_city = os.getenv("TARGET_CITY", "Paris")
        self.target_country = os.getenv("TARGET_COUNTRY", "France")
        self.max_restaurants = int(os.getenv("MAX_RESTAURANTS", "60"))
        
        # RequÃªtes diversifiÃ©es pour un dashboard de qualitÃ©
        self.diverse_queries = [
            "fine dining restaurants",      # Restaurants haut de gamme (4.5-5.0)
            "restaurants",                  # Restaurants classiques (4.0-4.5)
            "fast food",                   # Fast food (3.0-4.0)
            "cheap eats budget restaurants", # Restaurants pas chers (2.5-4.0)
            "street food food trucks",      # Street food (2.0-4.0)
            "bars pubs bistros"            # Bars/bistros (3.0-4.5)
        ]
        
        # Configuration de l'API Google Places
        self.places_base_url = "https://maps.googleapis.com/maps/api/place"
    
    def validate_config(self):
        """VÃ©rifie que la configuration est complÃ¨te"""
        logger.info("ğŸ” Validation de la configuration...")
        
        # VÃ©rifier la clÃ© API Google Places (obligatoire)
        if not self.google_api_key:
            logger.error("âŒ ERREUR : ClÃ© API Google Places manquante !")
            logger.error("ğŸ’¡ Ajoutez GOOGLE_PLACES_API_KEY dans config/.env")
            logger.error("ğŸ”— Obtenez votre clÃ© sur : https://console.cloud.google.com/")
            raise ValueError("ClÃ© API Google Places requise")
        
        # AWS est optionnel pour commencer
        if not self.s3_bucket:
            logger.warning("âš ï¸ Bucket S3 non configurÃ© - pas d'upload AWS")
        
        logger.info("âœ… Configuration validÃ©e")
    
    def setup_directories(self):
        """CrÃ©e les dossiers nÃ©cessaires pour sauvegarder les donnÃ©es"""
        directories = ["data", "logs"]
        
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)
                logger.info(f"ğŸ“ Dossier crÃ©Ã© : {directory}")
    
    def search_restaurants(self):
        """
        Ã‰TAPE 1 : Recherche des restaurants diversifiÃ©s avec Google Places
        
        Returns:
            list: Liste des restaurants trouvÃ©s
        """
        logger.info(f"ğŸ” Ã‰TAPE 1 : Recherche diversifiÃ©e de {self.max_restaurants} restaurants Ã  {self.target_city}...")
        
        # URL pour la recherche de lieux
        url = f"{self.places_base_url}/textsearch/json"
        
        # DiffÃ©rents types de recherches pour plus de diversitÃ©
        search_queries = [
            f"restaurants {self.target_city}",  # Restaurants classiques
            f"fast food {self.target_city}",   # Fast food (notes plus basses)
            f"cafes {self.target_city}",       # CafÃ©s  
            f"bars {self.target_city}",        # Bars
            f"cheap restaurants {self.target_city}",  # Restaurants pas chers
            f"food trucks {self.target_city}",        # Food trucks
        ]
        
        all_restaurants = []
        
        try:
            # Faire plusieurs requÃªtes pour diversifier les rÃ©sultats
            restaurants_per_query = self.max_restaurants // len(search_queries)
            
            for i, query in enumerate(search_queries):
                if len(all_restaurants) >= self.max_restaurants:
                    break
                    
                logger.info(f"ğŸ“¡ RequÃªte {i+1}/{len(search_queries)}: {query}")
                
                params = {
                    "query": query,
                    "type": "restaurant", 
                    "key": self.google_api_key,
                    "language": "fr"
                }
                
                response = requests.get(url, params=params)
                
                                if response.status_code == 200:
                    data = response.json()
                    
                    if data["status"] == "OK":
                        restaurants = data.get("results", [])
                        # Ã‰viter les doublons
                        existing_ids = {r.get("place_id") for r in all_restaurants}
                        new_restaurants = [r for r in restaurants if r.get("place_id") not in existing_ids]
                        all_restaurants.extend(new_restaurants)
                        
                        logger.info(f"âœ… {len(new_restaurants)} nouveaux restaurants trouvÃ©s !")
                        
                        # Afficher quelques exemples pour vÃ©rifier
                        for i, restaurant in enumerate(new_restaurants[:2]):
                            name = restaurant.get("name", "Nom inconnu")
                            rating = restaurant.get("rating", 0)
                            user_ratings_total = restaurant.get("user_ratings_total", 0)
                            logger.info(f"   {i+1}. {name} - {rating}â­ ({user_ratings_total} avis)")
                        
                        # Pause entre les requÃªtes
                        if i < len(search_queries) - 1:
                            time.sleep(1)
                    
                    while (next_page_token and 
                           len(all_restaurants) < self.max_restaurants and 
                           page_count < 6):  # Limite Ã  6 pages max (60 restaurants)
                        
                        logger.info(f"ğŸ“„ RÃ©cupÃ©ration de la page {page_count + 1}...")
                        time.sleep(2)  # Google exige une pause entre les requÃªtes de pagination
                        
                        next_params = {
                            "pagetoken": next_page_token,
                            "key": self.google_api_key
                        }
                        
                        next_response = requests.get(url, params=next_params)
                        
                        if next_response.status_code == 200:
                            next_data = next_response.json()
                            if next_data["status"] == "OK":
                                next_restaurants = next_data.get("results", [])
                                all_restaurants.extend(next_restaurants)
                                next_page_token = next_data.get("next_page_token")
                                page_count += 1
                                logger.info(f"   âœ… +{len(next_restaurants)} restaurants supplÃ©mentaires")
                            else:
                                break
                        else:
                            break
                    
                    # Limiter au nombre demandÃ©
                    all_restaurants = all_restaurants[:self.max_restaurants]
                    logger.info(f"âœ… Total final : {len(all_restaurants)} restaurants")
                    
                    return all_restaurants
                
                else:
                    logger.error(f"âŒ Erreur API Google Places : {data['status']}")
                    if "error_message" in data:
                        logger.error(f"   Message : {data['error_message']}")
                    return []
            
            else:
                logger.error(f"âŒ Erreur HTTP : {response.status_code}")
                logger.error(f"   Message : {response.text}")
                return []
        
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la recherche : {str(e)}")
            return []
    
    def get_place_details(self, place_id, place_name):
        """
        RÃ©cupÃ¨re les dÃ©tails complets d'un restaurant (y compris les avis)
        
        Args:
            place_id (str): ID Google Places du restaurant
            place_name (str): Nom du restaurant (pour les logs)
            
        Returns:
            dict: DÃ©tails complets du restaurant avec avis
        """
        logger.info(f"ğŸ“‹ RÃ©cupÃ©ration des dÃ©tails pour : {place_name}")
        
        # URL pour les dÃ©tails d'un lieu
        url = f"{self.places_base_url}/details/json"
        
        # ParamÃ¨tres pour obtenir les dÃ©tails + avis
        params = {
            "place_id": place_id,
            "fields": "place_id,name,rating,user_ratings_total,reviews,formatted_address,geometry,types,price_level,opening_hours,formatted_phone_number,website,photos",
            "key": self.google_api_key,
            "language": "fr"  # Avis en franÃ§ais si disponible
        }
        
        try:
            # Faire la requÃªte
            response = requests.get(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                
                if data["status"] == "OK":
                    result = data.get("result", {})
                    reviews = result.get("reviews", [])
                    
                    logger.info(f"   âœ… DÃ©tails rÃ©cupÃ©rÃ©s avec {len(reviews)} avis")
                    return result
                
                else:
                    logger.warning(f"   âš ï¸ Erreur API : {data['status']} pour {place_name}")
                    return {}
            
            else:
                logger.warning(f"   âš ï¸ Erreur HTTP {response.status_code} pour {place_name}")
                return {}
        
        except Exception as e:
            logger.error(f"   âŒ Erreur : {str(e)}")
            return {}
    
    def collect_all_details(self, restaurants):
        """
        Ã‰TAPE 2 : Collecte les dÃ©tails complets pour tous les restaurants
        
        Args:
            restaurants (list): Liste des restaurants de base
            
        Returns:
            list: Liste des restaurants avec dÃ©tails complets et avis
        """
        logger.info("ğŸ“‹ Ã‰TAPE 2 : Collecte des dÃ©tails pour tous les restaurants...")
        
        detailed_restaurants = []
        
        # Utiliser tqdm pour afficher une barre de progression
        for restaurant in tqdm(restaurants, desc="Collecte des dÃ©tails"):
            place_id = restaurant.get("place_id")
            place_name = restaurant.get("name", "Restaurant inconnu")
            
            if place_id:
                # RÃ©cupÃ©rer les dÃ©tails complets
                details = self.get_place_details(place_id, place_name)
                
                if details:
                    # Fusionner les donnÃ©es de base avec les dÃ©tails
                    restaurant_complete = {**restaurant, **details}
                    detailed_restaurants.append(restaurant_complete)
                else:
                    # Garder au moins les donnÃ©es de base si les dÃ©tails Ã©chouent
                    detailed_restaurants.append(restaurant)
                
                # Petite pause pour respecter les limites de l'API
                time.sleep(0.1)
        
        logger.info(f"âœ… {len(detailed_restaurants)} restaurants avec dÃ©tails collectÃ©s")
        return detailed_restaurants
    
    def prepare_data_for_export(self, restaurants):
        """
        Ã‰TAPE 3 : PrÃ©pare les donnÃ©es pour l'export (nettoyage et structuration)
        
        Args:
            restaurants (list): Liste des restaurants complets
            
        Returns:
            tuple: (restaurants_df, reviews_df) DataFrames pandas
        """
        logger.info("ğŸ§¹ Ã‰TAPE 3 : PrÃ©paration des donnÃ©es pour l'export...")
        
        # === PRÃ‰PARATION DES DONNÃ‰ES RESTAURANTS ===
        restaurants_clean = []
        all_reviews = []
        
        for restaurant in restaurants:
            # Extraire les informations restaurants de faÃ§on sÃ©curisÃ©e
            clean_restaurant = {
                "place_id": restaurant.get("place_id", ""),
                "name": restaurant.get("name", ""),
                "rating": restaurant.get("rating", 0),
                "user_ratings_total": restaurant.get("user_ratings_total", 0),
                "price_level": restaurant.get("price_level", ""),
                "formatted_address": restaurant.get("formatted_address", ""),
                "formatted_phone_number": restaurant.get("formatted_phone_number", ""),
                "website": restaurant.get("website", ""),
                
                # Types/catÃ©gories
                "types": ", ".join(restaurant.get("types", [])),
                "primary_type": restaurant.get("types", [""])[0] if restaurant.get("types") else "",
                
                # GÃ©olocalisation
                "latitude": restaurant.get("geometry", {}).get("location", {}).get("lat", ""),
                "longitude": restaurant.get("geometry", {}).get("location", {}).get("lng", ""),
                
                # Horaires
                "opening_hours": str(restaurant.get("opening_hours", {}).get("weekday_text", [])),
                
                # MÃ©tadonnÃ©es
                "collected_at": datetime.now().isoformat(),
                "data_source": "google_places"
            }
            restaurants_clean.append(clean_restaurant)
            
            # === EXTRAIRE LES AVIS ===
            reviews = restaurant.get("reviews", [])
            for review in reviews:
                clean_review = {
                    "place_id": restaurant.get("place_id", ""),
                    "restaurant_name": restaurant.get("name", ""),
                    
                    # Contenu de l'avis
                    "author_name": review.get("author_name", ""),
                    "author_url": review.get("author_url", ""),
                    "language": review.get("language", ""),
                    "profile_photo_url": review.get("profile_photo_url", ""),
                    "rating": review.get("rating", 0),
                    "relative_time_description": review.get("relative_time_description", ""),
                    "text": review.get("text", ""),
                    "time": review.get("time", 0),
                    
                    # MÃ©tadonnÃ©es
                    "collected_at": datetime.now().isoformat(),
                    "data_source": "google_places"
                }
                all_reviews.append(clean_review)
        
        # Convertir en DataFrames pandas pour faciliter l'export
        restaurants_df = pd.DataFrame(restaurants_clean)
        reviews_df = pd.DataFrame(all_reviews)
        
        logger.info(f"âœ… DonnÃ©es prÃ©parÃ©es : {len(restaurants_df)} restaurants, {len(reviews_df)} avis")
        
        return restaurants_df, reviews_df
    
    def save_data_locally(self, restaurants_df, reviews_df, all_data):
        """
        Ã‰TAPE 4 : Sauvegarde les donnÃ©es en local (CSV et JSON)
        
        Args:
            restaurants_df: DataFrame des restaurants
            reviews_df: DataFrame des avis
            all_data: DonnÃ©es complÃ¨tes en format dictionnaire
        """
        logger.info("ğŸ’¾ Ã‰TAPE 4 : Sauvegarde des donnÃ©es en local...")
        
        # CrÃ©er un timestamp pour les noms de fichiers
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # === SAUVEGARDE CSV ===
            restaurants_csv = f"data/restaurants_google_{timestamp}.csv"
            reviews_csv = f"data/reviews_google_{timestamp}.csv"
            
            restaurants_df.to_csv(restaurants_csv, index=False, encoding='utf-8')
            reviews_df.to_csv(reviews_csv, index=False, encoding='utf-8')
            
            logger.info(f"âœ… CSV sauvegardÃ©s :")
            logger.info(f"   - Restaurants : {restaurants_csv}")
            logger.info(f"   - Avis : {reviews_csv}")
            
            # === SAUVEGARDE JSON ===
            json_file = f"data/google_places_data_complete_{timestamp}.json"
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… JSON sauvegardÃ© : {json_file}")
            
            # Retourner les noms de fichiers pour l'upload S3
            return {
                "restaurants_csv": restaurants_csv,
                "reviews_csv": reviews_csv,
                "json_file": json_file
            }
        
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la sauvegarde : {str(e)}")
            return None
    
    def upload_to_s3(self, file_paths):
        """
        Ã‰TAPE 5 : Upload les fichiers vers AWS S3
        
        Args:
            file_paths (dict): Chemins des fichiers Ã  uploader
        """
        if not self.s3_bucket:
            logger.warning("â© Ã‰TAPE 5 : Upload S3 ignorÃ© (bucket non configurÃ©)")
            return
        
        logger.info("â˜ï¸ Ã‰TAPE 5 : Upload vers AWS S3...")
        
        try:
            # CrÃ©er le client S3
            s3_client = boto3.client(
                's3',
                aws_access_key_id=self.aws_access_key,
                aws_secret_access_key=self.aws_secret_key,
                region_name=self.aws_region
            )
            
            # VÃ©rifier/crÃ©er le bucket
            try:
                s3_client.head_bucket(Bucket=self.s3_bucket)
                logger.info(f"âœ… Bucket {self.s3_bucket} trouvÃ©")
            except:
                logger.info(f"ğŸ“¦ CrÃ©ation du bucket {self.s3_bucket}...")
                s3_client.create_bucket(Bucket=self.s3_bucket)
            
            # Uploader chaque fichier
            for file_type, file_path in file_paths.items():
                if file_path and os.path.exists(file_path):
                    # Nom du fichier dans S3
                    s3_key = f"google-places-data/{os.path.basename(file_path)}"
                    
                    logger.info(f"ğŸ“¤ Upload de {file_path}...")
                    s3_client.upload_file(file_path, self.s3_bucket, s3_key)
                    logger.info(f"   âœ… UploadÃ© vers s3://{self.s3_bucket}/{s3_key}")
            
            logger.info("ğŸ‰ Tous les fichiers uploadÃ©s vers S3 !")
        
        except Exception as e:
            logger.error(f"âŒ Erreur upload S3 : {str(e)}")
            logger.warning("ğŸ’¡ VÃ©rifiez vos credentials AWS et le nom du bucket")
    
    def run(self):
        """
        MÃ‰THODE PRINCIPALE : Lance tout le processus de collecte
        """
        logger.info("ğŸš€ DÃ‰BUT DE LA COLLECTE DE DONNÃ‰ES GOOGLE PLACES")
        logger.info("=" * 60)
        
        try:
            # Ã‰TAPE 1 : Rechercher les restaurants
            restaurants = self.search_restaurants()
            
            if not restaurants:
                logger.error("âŒ Aucun restaurant trouvÃ© - arrÃªt du processus")
                return
            
            # Ã‰TAPE 2 : Collecter les dÃ©tails complets
            detailed_restaurants = self.collect_all_details(restaurants)
            
            # Ã‰TAPE 3 : PrÃ©parer les donnÃ©es
            restaurants_df, reviews_df = self.prepare_data_for_export(detailed_restaurants)
            
            # CrÃ©er le dataset complet
            complete_data = {
                "metadata": {
                    "city": self.target_city,
                    "country": self.target_country,
                    "collection_date": datetime.now().isoformat(),
                    "total_restaurants": len(detailed_restaurants),
                    "total_reviews": len(reviews_df),
                    "api_source": "google_places"
                },
                "restaurants": detailed_restaurants
            }
            
            # Ã‰TAPE 4 : Sauvegarder localement
            file_paths = self.save_data_locally(restaurants_df, reviews_df, complete_data)
            
            # Ã‰TAPE 5 : Upload vers S3
            if file_paths:
                self.upload_to_s3(file_paths)
            
            # RAPPORT FINAL
            logger.info("ğŸ“Š RAPPORT FINAL")
            logger.info("=" * 40)
            logger.info(f"ğŸª Restaurants collectÃ©s : {len(detailed_restaurants)}")
            logger.info(f"ğŸ’¬ Avis collectÃ©s : {len(reviews_df)}")
            logger.info(f"ğŸ“ Fichiers sauvegardÃ©s : {len(file_paths) if file_paths else 0}")
            logger.info("ğŸ‰ COLLECTE TERMINÃ‰E AVEC SUCCÃˆS !")
        
        except KeyboardInterrupt:
            logger.info("â¹ï¸ Collecte interrompue par l'utilisateur")
        except Exception as e:
            logger.error(f"ğŸ’¥ Erreur fatale : {str(e)}")


def main():
    """Point d'entrÃ©e principal du script"""
    print("ğŸ—ºï¸ Collecteur de DonnÃ©es Google Places - Version DÃ©butant")
    print("=" * 60)
    
    # CrÃ©er et lancer le collecteur
    collector = GooglePlacesCollector()
    collector.run()


# Lancer le script si exÃ©cutÃ© directement
if __name__ == "__main__":
    main() 